@manual{schweinberger2023svm,
  author = {Schweinberger, Martin},
  title = {Semantic Vector Space Models in R},
  note = {https://ladal.edu.au/svm.html},
  year = {2023},
  organization = {The University of Queensland, Australia. School of Languages and Cultures},
}


@misc{jurriaan_nlp_2020,
	title = {{NLP} with {R} part 2: {Training} {Word} {Embedding} models and visualize results},
	url = {https://medium.com/cmotions/nlp-with-r-part-2-training-word-embedding-models-and-visualize-results-ae444043e234},
	author = {Jurriaan, Nagelkerke and van Gils, Wouter},
	month = nov,
	year = {2020},
}

@misc{benoit_replication_nodate,
	title = {Replication: word embedding ({gloVe}/word2vec)},
	url = {https://quanteda.io/articles/pkgdown/replication/text2vec.html},
	author = {Benoit, Ken and Wang, Haiyan and Watanabe, Kohei},
}

@misc{hvitfeldt_supervised_2022,
	title = {Supervised {Machine} {Learning} for {Text} {Analysis} in {R}. {Acoompanying} online tutorial, section 5.},
	url = {https://smltar.com/embeddings.html},
	author = {Hvitfeldt, Emil and Silge, Julia},
	year = {2022},
	doi = {10.1201/9781003093459},
}

@misc{bail_word_nodate,
	title = {Word {Embeddings}},
	url = {https://cbail.github.io/textasdata/word2vec/rmarkdown/word2vec.html},
	author = {Bail, Christopher A.},
	doi = {10.1201/9781003093459},
}

@article{chung-hong_chan_grafzahl_2023,
	title = {grafzahl: fine-tuning {Transformers} fortext data from within {R}},
	volume = {5},
	issn = {2665-9085},
	shorttitle = {grafzahl},
	url = {https://www.aup-online.com/content/journals/10.5117/CCR2023.1.003.CHAN},
	doi = {10.5117/CCR2023.1.003.CHAN},
	language = {en},
	number = {1},
	urldate = {2023-07-25},
	journal = {Computational Communication Research},
	author = {{Chung-hong Chan}},
	month = jan,
	year = {2023},
	pages = {76},
}


@article{kjell_text-package_2023,
	title = {The text-package: {An} {R}-package for analyzing and visualizing human language using natural language processing and transformers.},
	issn = {1939-1463, 1082-989X},
	shorttitle = {The text-package},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000542},
	doi = {10.1037/met0000542},
	language = {en},
	urldate = {2023-07-25},
	journal = {Psychological Methods},
	author = {Kjell, Oscar and Giorgi, Salvatore and Schwartz, H. Andrew},
	month = may,
	year = {2023},
}



@inproceedings{wendlandt_factors_2018,
	address = {New Orleans, Louisiana},
	title = {Factors {Influencing} the {Surprising} {Instability} of {Word} {Embeddings}},
	url = {http://aclweb.org/anthology/N18-1190},
	doi = {10.18653/v1/N18-1190},
	language = {en},
	urldate = {2023-07-25},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Wendlandt, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
	year = {2018},
	pages = {2092--2102},
}

@article{antoniak_evaluating_2018,
	title = {Evaluating the {Stability} of {Embedding}-based {Word} {Similarities}},
	volume = {6},
	issn = {2307-387X},
	url = {https://direct.mit.edu/tacl/article/43418},
	doi = {10.1162/tacl_a_00008},
	abstract = {Word embeddings are increasingly being used as a tool to study word associations in specific corpora. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents. We find that nearest-neighbor distances are highly sensitive to small changes in the training corpus for a variety of algorithms. For all methods, including specific documents in the training set can result in substantial variations. We show that these effects are more prominent for smaller training corpora. We recommend that users never rely on single embedding models for distance calculations, but rather average over multiple bootstrap samples, especially for small corpora.},
	language = {en},
	urldate = {2023-07-25},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Antoniak, Maria and Mimno, David},
	month = dec,
	year = {2018},
	pages = {107--119},
}


@article{wilkerson_large-scale_2017,
	title = {Large-{Scale} {Computerized} {Text} {Analysis} in {Political} {Science}: {Opportunities} and {Challenges}},
	volume = {20},
	issn = {1094-2939, 1545-1577},
	shorttitle = {Large-{Scale} {Computerized} {Text} {Analysis} in {Political} {Science}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-polisci-052615-025542},
	doi = {10.1146/annurev-polisci-052615-025542},
	abstract = {Text has always been an important data source in political science. What has changed in recent years is the feasibility of investigating large amounts of text quantitatively. The internet provides political scientists with more data than their mentors could have imagined, and the research community is providing accessible text analysis software packages, along with training and support. As a result, text-as-data research is becoming mainstream in political science. Scholars are tapping new data sources, they are employing more diverse methods, and they are becoming critical consumers of findings based on those methods. In this article, we first describe the four stages of a typical text-as-data project. We then review recent political science applications and explore one important methodological challenge—topic model instability—in greater detail.},
	language = {en},
	number = {1},
	urldate = {2022-02-04},
	journal = {Annual Review of Political Science},
	author = {Wilkerson, John and Casas, Andreu},
	month = may,
	year = {2017},
	pages = {529--544},
}


@incollection{alvarez_navigating_2016,
	address = {Cambridge},
	title = {Navigating the {Local} {Modes} of {Big} {Data}: {The} {Case} of {Topic} {Models}},
	isbn = {978-1-316-25734-0},
	shorttitle = {Navigating the {Local} {Modes} of {Big} {Data}},
	url = {https://www.cambridge.org/core/product/identifier/CBO9781316257340A009/type/book_part},
	urldate = {2020-02-06},
	booktitle = {Computational {Social} {Science}},
	publisher = {Cambridge University Press},
	author = {Roberts, Margaret E. and Stewart, Brandon M. and Tingley, Dustin},
	editor = {Alvarez, R. Michael},
	year = {2016},
	doi = {10.1017/CBO9781316257340.004},
	pages = {51--97},
}


@article{song_validations_2020,
	title = {In {Validations} {We} {Trust}? {The} {Impact} of {Imperfect} {Human} {Annotations} as a {Gold} {Standard} on the {Quality} of {Validation} of {Automated} {Content} {Analysis}},
	volume = {37},
	issn = {1058-4609, 1091-7675},
	shorttitle = {In {Validations} {We} {Trust}?},
	url = {https://www.tandfonline.com/doi/full/10.1080/10584609.2020.1723752},
	doi = {10.1080/10584609.2020.1723752},
	language = {en},
	number = {4},
	urldate = {2022-01-27},
	journal = {Political Communication},
	author = {Song, Hyunjin and Tolochko, Petro and Eberl, Jakob-Moritz and Eisele, Olga and Greussing, Esther and Heidenreich, Tobias and Lind, Fabienne and Galyga, Sebastian and Boomgaarden, Hajo G.},
	month = jul,
	year = {2020},
	pages = {550--572},
}


@article{grimmer_text_2013,
	title = {Text as {Data}: {The} {Promise} and {Pitfalls} of {Automatic} {Content} {Analysis} {Methods} for {Political} {Texts}},
	volume = {21},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Text as {Data}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198700013401/type/journal_article},
	doi = {10.1093/pan/mps028},
	abstract = {Politics and political conflict often occur in the written and spoken word. Scholars have long recognized this, but the massive costs of analyzing even moderately sized collections of texts have hindered their use in political science research. Here lies the promise of automated text analysis: it substantially reduces the costs of analyzing large collections of text. We provide a guide to this exciting new area of research and show how, in many instances, the methods have already obtained part of their promise. But there are pitfalls to using automated methods—they are no substitute for careful thought and close reading and require extensive and problem-specific validation. We survey a wide range of new methods, provide guidance on how to validate the output of the models, and clarify misconceptions and errors in the literature. To conclude, we argue that for automated text methods to become a standard tool for political scientists, methodologists must contribute new methods and new methods of validation.},
	language = {en},
	number = {3},
	urldate = {2022-01-28},
	journal = {Political Analysis},
	author = {Grimmer, Justin and Stewart, Brandon M.},
	year = {2013},
	pages = {267--297},
}


@Manual{mullen_2020,
	title = {textreuse: Detect Text Reuse and Document Similarity},
	author = {Lincoln Mullen},
	year = {2020},
	note = {https://docs.ropensci.org/textreuse, https://github.com/ropensci/textreuse},
	}

@article{mozer_matching_2020,
	title = {Matching with {Text} {Data}: {An} {Experimental} {Evaluation} of {Methods} for {Matching} {Documents} and of {Measuring} {Match} {Quality}},
	volume = {28},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Matching with {Text} {Data}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198720000017/type/journal_article},
	doi = {10.1017/pan.2020.1},
	abstract = {Matching for causal inference is a well-studied problem, but standard methods fail when the units to match are text documents: the high-dimensional and rich nature of the data renders exact matching infeasible, causes propensity scores to produce incomparable matches, and makes assessing match quality difficult. In this paper, we characterize a framework for matching text documents that decomposes existing methods into (1) the choice of text representation and (2) the choice of distance metric. We investigate how different choices within this framework affect both the quantity and quality of matches identified through a systematic multifactor evaluation experiment using human subjects. Altogether, we evaluate over 100 unique text-matching methods along with 5 comparison methods taken from the literature. Our experimental results identify methods that generate matches with higher subjective match quality than current state-of-the-art techniques. We enhance the precision of these results by developing a predictive model to estimate the match quality of pairs of text documents as a function of our various distance scores. This model, which we find successfully mimics human judgment, also allows for approximate and unsupervised evaluation of new procedures in our context. We then employ the identified best method to illustrate the utility of text matching in two applications. First, we engage with a substantive debate in the study of media bias by using text matching to control for topic selection when comparing news articles from thirteen news sources. We then show how conditioning on text data leads to more precise causal inferences in an observational study examining the effects of a medical intervention.},
	language = {en},
	number = {4},
	urldate = {2023-07-24},
	journal = {Political Analysis},
	author = {Mozer, Reagan and Miratrix, Luke and Kaufman, Aaron Russell and Jason Anastasopoulos, L.},
	month = oct,
	year = {2020},
	pages = {445--468},
}

@book{salton_smart_1971,
	address = {Upper Saddle River, NJ},
	title = {The {SMART} retrieval system - experiments in automatic document processing},
	publisher = {Prentice-Hall, Inc.},
	author = {Salton, Gerard},
	year = {1971},
}


@manual{schweinberger2023coll,
  author = {Schweinberger, Martin},
  title = {Analyzing Co-Occurrences and Collocations in R},
  note = {https://ladal.edu.au/coll.html},
  year = {2023},
  organization = {The University of Queensland, Australia. School of Languages and Cultures},
}

@manual{schweinberger2023postag,
  author = {Schweinberger, Martin},
  title = {Part-of-Speech Tagging and Dependency Parsing with R},
  note = {https://ladal.edu.au/postag.html},
  year = {2023},
  organization = {The University of Queensland, School of Languages and Cultures},
}

@article{nicholls_detecting_2019,
	title = {Detecting {Textual} {Reuse} in {News} {Stories}, {At} {Scale}},
	volume = {13},
	journal = {International Journal of Communication},
	author = {Nicholls, Tom},
	year = {2019},
	pages = {4173--4197},
}

@inproceedings{papakyriakopoulos_bias_2020,
	address = {Barcelona Spain},
	title = {Bias in word embeddings},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372843},
	doi = {10.1145/3351095.3372843},
	language = {en},
	urldate = {2023-07-21},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Papakyriakopoulos, Orestis and Hegelich, Simon and Serrano, Juan Carlos Medina and Marco, Fabienne},
	month = jan,
	year = {2020},
	pages = {446--457},
}

@article{stoltz_cultural_2021,
	title = {Cultural cartography with word embeddings},
	volume = {88},
	issn = {0304422X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304422X21000504},
	doi = {10.1016/j.poetic.2021.101567},
	language = {en},
	urldate = {2023-07-21},
	journal = {Poetics},
	author = {Stoltz, Dustin S. and Taylor, Marshall A.},
	month = oct,
	year = {2021},
	pages = {101567},
}

@article{arseniev-koehler_theoretical_2022,
	title = {Theoretical {Foundations} and {Limits} of {Word} {Embeddings}: {What} {Types} of {Meaning} can {They} {Capture}?},
	issn = {0049-1241, 1552-8294},
	shorttitle = {Theoretical {Foundations} and {Limits} of {Word} {Embeddings}},
	url = {http://journals.sagepub.com/doi/10.1177/00491241221140142},
	doi = {10.1177/00491241221140142},
	abstract = {Measuring meaning is a central problem in cultural sociology and word embeddings may offer powerful new tools to do so. But like any tool, they build on and exert theoretical assumptions. In this paper, I theorize the ways in which word embeddings model three core premises of a structural linguistic theory of meaning: that meaning is coherent, relational, and may be analyzed as a static system. In certain ways, word embeddings are vulnerable to the enduring critiques of these premises. In other ways, word embeddings offer novel solutions to these critiques. More broadly, formalizing the study of meaning with word embeddings offers theoretical opportunities to clarify core concepts and debates in cultural sociology, such as the coherence of meaning. Just as network analysis specified the once vague notion of social relations, formalizing meaning with embeddings can push us to specify and reimagine meaning itself.},
	language = {en},
	urldate = {2023-07-21},
	journal = {Sociological Methods \& Research},
	author = {Arseniev-Koehler, Alina},
	month = dec,
	year = {2022},
	pages = {004912412211401},
}

@article{kozlowski_geometry_2019,
	title = {The {Geometry} of {Culture}: {Analyzing} the {Meanings} of {Class} through {Word} {Embeddings}},
	volume = {84},
	issn = {0003-1224, 1939-8271},
	shorttitle = {The {Geometry} of {Culture}},
	url = {http://journals.sagepub.com/doi/10.1177/0003122419877135},
	doi = {10.1177/0003122419877135},
	abstract = {We argue word embedding models are a useful tool for the study of culture using a historical analysis of shared understandings of social class as an empirical case. Word embeddings represent semantic relations between words as relationships between vectors in a high-dimensional space, specifying a relational model of meaning consistent with contemporary theories of culture. Dimensions induced by word differences ( rich – poor) in these spaces correspond to dimensions of cultural meaning, and the projection of words onto these dimensions reflects widely shared associations, which we validate with surveys. Analyzing text from millions of books published over 100 years, we show that the markers of class continuously shifted amidst the economic transformations of the twentieth century, yet the basic cultural dimensions of class remained remarkably stable. The notable exception is education, which became tightly linked to affluence independent of its association with cultivated taste.},
	language = {en},
	number = {5},
	urldate = {2023-07-21},
	journal = {American Sociological Review},
	author = {Kozlowski, Austin C. and Taddy, Matt and Evans, James A.},
	month = oct,
	year = {2019},
	pages = {905--949},
}

@article{rodman_timely_2020,
	title = {A {Timely} {Intervention}: {Tracking} the {Changing} {Meanings} of {Political} {Concepts} with {Word} {Vectors}},
	volume = {28},
	issn = {1047-1987, 1476-4989},
	shorttitle = {A {Timely} {Intervention}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198719000238/type/journal_article},
	doi = {10.1017/pan.2019.23},
	abstract = {Word vectorization is an emerging text-as-data method that shows great promise for automating the analysis of semantics—here, the cultural meanings of words—in large volumes of text. Yet successes with this method have largely been confined to massive corpora where the meanings of words are presumed to be fixed. In political science applications, however, many corpora are comparatively small and many interesting questions hinge on the recognition that meaning changes over time. Together, these two facts raise vexing methodological challenges. Can word vectors trace the changing cultural meanings of words in typical small corpora use cases? I test four time-sensitive implementations of word vectors (
              word2vec
              ) against a gold standard developed from a modest data set of 161 years of newspaper coverage. I find that one implementation method clearly outperforms the others in matching human assessments of how public dialogues around equality in America have changed over time. In addition, I suggest best practices for using
              word2vec
              to study small corpora for time series questions, including bootstrap resampling of documents and pretraining of vectors. I close by showing that
              word2vec
              allows granular analysis of the changing meaning of words, an advance over other common text-as-data methods for semantic research questions.},
	language = {en},
	number = {1},
	urldate = {2023-07-19},
	journal = {Political Analysis},
	author = {Rodman, Emma},
	month = jan,
	year = {2020},
	pages = {87--111},
}

@article{muller_differential_2023,
	title = {Differential {Racism} in the {News}: {Using} {Semi}-{Supervised} {Machine} {Learning} to {Distinguish} {Explicit} and {Implicit} {Stigmatization} of {Ethnic} and {Religious} {Groups} in {Journalistic} {Discourse}},
	volume = {40},
	issn = {1058-4609, 1091-7675},
	shorttitle = {Differential {Racism} in the {News}},
	url = {https://www.tandfonline.com/doi/full/10.1080/10584609.2023.2193146},
	doi = {10.1080/10584609.2023.2193146},
	language = {en},
	number = {4},
	urldate = {2023-07-19},
	journal = {Political Communication},
	author = {Müller, Philipp and Chan, Chung-Hong and Ludwig, Katharina and Freudenthaler, Rainer and Wessler, Hartmut},
	month = jul,
	year = {2023},
	pages = {396--414},
}

@article{caliskan_semantics_2017,
	title = {Semantics derived automatically from language corpora contain human-like biases},
	volume = {356},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aal4230},
	doi = {10.1126/science.aal4230},
	abstract = {Machines learn what people know implicitly
            
              AlphaGo has demonstrated that a machine can learn how to do things that people spend many years of concentrated study learning, and it can rapidly learn how to do them better than any human can. Caliskan
              et al.
              now show that machines can learn word associations from written texts and that these associations mirror those learned by humans, as measured by the Implicit Association Test (IAT) (see the Perspective by Greenwald). Why does this matter? Because the IAT has predictive value in uncovering the association between concepts, such as pleasantness and flowers or unpleasantness and insects. It can also tease out attitudes and beliefs—for example, associations between female names and family or male names and career. Such biases may not be expressed explicitly, yet they can prove influential in behavior.
            
            
              Science
              , this issue p.
              183
              ; see also p.
              133
            
          , 
            Computers can learn which words go together more or less often and can thus mimic human performance on a test of implicit bias.
          , 
            Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.},
	language = {en},
	number = {6334},
	urldate = {2023-07-19},
	journal = {Science},
	author = {Caliskan, Aylin and Bryson, Joanna J. and Narayanan, Arvind},
	month = apr,
	year = {2017},
	pages = {183--186},
}

@article{hargrave_no_2022,
	title = {No {Longer} {Conforming} to {Stereotypes}? {Gender}, {Political} {Style} and {Parliamentary} {Debate} in the {UK}},
	volume = {52},
	issn = {0007-1234, 1469-2112},
	shorttitle = {No {Longer} {Conforming} to {Stereotypes}?},
	url = {https://www.cambridge.org/core/product/identifier/S0007123421000648/type/journal_article},
	doi = {10.1017/S0007123421000648},
	abstract = {Abstract
            Research on political style suggests that where women make arguments that are more emotional, empathetic and positive, men use language that is more analytical, aggressive and complex. However, existing work does not consider how gendered patterns of style vary over time. Focusing on the UK, we argue that pressures for female politicians to conform to stereotypically ‘feminine’ styles have diminished in recent years. To test this argument, we describe novel quantitative text-analysis approaches for measuring a diverse set of styles at scale in political speech data. Analysing UK parliamentary debates between 1997 and 2019, we show that the debating styles of female MPs have changed substantially over time, as women in Parliament have increasingly adopted stylistic traits that are typically associated with ‘masculine’ stereotypes of communication. Our findings imply that prominent gender-based stereotypes of politicians' behaviour are significantly worse descriptors of empirical reality now than they were in the past.},
	language = {en},
	number = {4},
	urldate = {2023-07-19},
	journal = {British Journal of Political Science},
	author = {Hargrave, Lotte and Blumenau, Jack},
	month = oct,
	year = {2022},
	pages = {1584--1601},
}

@article{chan_reproducible_2020,
	title = {Reproducible {Extraction} of {Cross}-lingual {Topics} (rectr)},
	volume = {14},
	issn = {1931-2458, 1931-2466},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2020.1812555},
	doi = {10.1080/19312458.2020.1812555},
	language = {en},
	number = {4},
	urldate = {2023-07-19},
	journal = {Communication Methods and Measures},
	author = {Chan, Chung-Hong and Zeng, Jing and Wessler, Hartmut and Jungblut, Marc and Welbers, Kasper and Bajjalieh, Joseph W and Van Atteveldt, Wouter and Althaus, Scott L.},
	month = oct,
	year = {2020},
	pages = {285--305},
}

@article{chan_sweater_2022,
	title = {sweater: {Speedy} {Word} {Embedding} {Association} {Test} {andExtras} {Using} {R}},
	volume = {7},
	issn = {2475-9066},
	shorttitle = {sweater},
	url = {https://joss.theoj.org/papers/10.21105/joss.04036},
	doi = {10.21105/joss.04036},
	number = {72},
	urldate = {2023-07-19},
	journal = {Journal of Open Source Software},
	author = {Chan, Chung-hong},
	month = apr,
	year = {2022},
	pages = {4036},
}

@article{rodriguez_embedding_2023,
	title = {Embedding {Regression}: {Models} for {Context}-{Specific} {Description} and {Inference}},
	issn = {0003-0554, 1537-5943},
	shorttitle = {Embedding {Regression}},
	url = {https://www.cambridge.org/core/product/identifier/S0003055422001228/type/journal_article},
	doi = {10.1017/S0003055422001228},
	abstract = {Social scientists commonly seek to make statements about how word use varies over circumstances—including time, partisan identity, or some other document-level covariate. For example, researchers might wish to know how Republicans and Democrats diverge in their understanding of the term “immigration.” Building on the success of pretrained language models, we introduce the à la carte on text (conText) embedding regression model for this purpose. This fast and simple method produces valid vector representations of how words are used—and thus what words “mean”—in different contexts. We show that it outperforms slower, more complicated alternatives and works well even with very few documents. The model also allows for hypothesis testing and statements about statistical significance. We demonstrate that it can be used for a broad range of important tasks, including understanding US polarization, historical legislative development, and sentiment detection. We provide open-source software for fitting the model.},
	language = {en},
	urldate = {2023-07-19},
	journal = {American Political Science Review},
	author = {Rodriguez, Pedro L. and Spirling, Arthur and Stewart, Brandon M.},
	month = jan,
	year = {2023},
	pages = {1--20},
}

@article{egami_how_2022,
	title = {How to make causal inferences using texts},
	volume = {8},
	issn = {2375-2548},
	url = {https://www.science.org/doi/10.1126/sciadv.abg2652},
	doi = {10.1126/sciadv.abg2652},
	abstract = {Text as data techniques offer a great promise: the ability to inductively discover measures that are useful for testing social science theories with large collections of text. Nearly all text-based causal inferences depend on a latent representation of the text, but we show that estimating this latent representation from the data creates underacknowledged risks: we may introduce an identification problem or overfit. To address these risks, we introduce a split-sample workflow for making rigorous causal inferences with discovered measures as treatments or outcomes. We then apply it to estimate causal effects from an experiment on immigration attitudes and a study on bureaucratic responsiveness.
          , 
            Identification challenges in causal inference with documents can be addressed with sample splitting.},
	language = {en},
	number = {42},
	urldate = {2023-07-25},
	journal = {Science Advances},
	author = {Egami, Naoki and Fong, Christian J. and Grimmer, Justin and Roberts, Margaret E. and Stewart, Brandon M.},
	month = oct,
	year = {2022},
	pages = {eabg2652},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1706.03762},
	doi = {10.48550/ARXIV.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2023-07-19},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	note = {Publisher: arXiv
Version Number: 5},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, Machine Learning (cs.LG)},
	annote = {Other
15 pages, 5 figures},
}

@article{wolf_huggingfaces_2019,
	title = {{HuggingFace}'s {Transformers}: {State}-of-the-art {Natural} {Language} {Processing}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {{HuggingFace}'s {Transformers}},
	url = {https://arxiv.org/abs/1910.03771},
	doi = {10.48550/ARXIV.1910.03771},
	abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. {\textbackslash}textit\{Transformers\} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. {\textbackslash}textit\{Transformers\} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at {\textbackslash}url\{https://github.com/huggingface/transformers\}.},
	urldate = {2023-07-19},
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
	year = {2019},
	note = {Publisher: arXiv
Version Number: 5},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences},
	annote = {Other
8 pages, 4 figures, more details at https://github.com/huggingface/transformers},
}

@misc{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	url = {http://arxiv.org/abs/1310.4546},
	abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	urldate = {2023-07-19},
	publisher = {arXiv},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = oct,
	year = {2013},
	note = {arXiv:1310.4546 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{schnabel_evaluation_2015,
	address = {Lisbon, Portugal},
	title = {Evaluation methods for unsupervised word embeddings},
	url = {http://aclweb.org/anthology/D15-1036},
	doi = {10.18653/v1/D15-1036},
	language = {en},
	urldate = {2023-07-19},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Schnabel, Tobias and Labutov, Igor and Mimno, David and Joachims, Thorsten},
	year = {2015},
	pages = {298--307},
}

@article{goldberg_primer_2016,
	title = {A {Primer} on {Neural} {Network} {Models} for {Natural} {Language} {Processing}},
	volume = {57},
	issn = {1076-9757},
	url = {https://jair.org/index.php/jair/article/view/11030},
	doi = {10.1613/jair.4992},
	abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
	urldate = {2023-07-19},
	journal = {Journal of Artificial Intelligence Research},
	author = {Goldberg, Yoav},
	month = nov,
	year = {2016},
	pages = {345--420},
}


@article{feder_causal_2022,
	title = {Causal {Inference} in {Natural} {Language} {Processing}: {Estimation}, {Prediction}, {Interpretation} and {Beyond}},
	volume = {10},
	issn = {2307-387X},
	shorttitle = {Causal {Inference} in {Natural} {Language} {Processing}},
	url = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00511/113490/Causal-Inference-in-Natural-Language-Processing},
	doi = {10.1162/tacl_a_00511},
	abstract = {Abstract
            A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the challenges and opportunities in the application of causal inference to the textual domain, with its unique properties. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects with text, encompassing settings where text is used as an outcome, treatment, or to address confounding. In addition, we explore potential uses of causal inference to improve the robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the NLP community.1},
	language = {en},
	urldate = {2023-07-25},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Feder, Amir and Keith, Katherine A. and Manzoor, Emaad and Pryzant, Reid and Sridhar, Dhanya and Wood-Doughty, Zach and Eisenstein, Jacob and Grimmer, Justin and Reichart, Roi and Roberts, Margaret E. and Stewart, Brandon M. and Veitch, Victor and Yang, Diyi},
	month = oct,
	year = {2022},
	pages = {1138--1158},
}


@inproceedings{bolukbasi_man_2016,
	title = {Man is to {Computer} {Programmer} as {Woman} is to {Homemaker}? {Debiasing} {Word} {Embeddings}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
	editor = {Lee, D. and Sugiyama, M. and Luxburg, U. and Guyon, I. and Garnett, R.},
	year = {2016},
}

@inproceedings{le_distributed_2014,
	address = {Bejing, China},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Distributed {Representations} of {Sentences} and {Documents}},
	volume = {32},
	url = {https://proceedings.mlr.press/v32/le14.html},
	abstract = {Many machine learning algorithms require the input to be represented as a fixed length feature vector. When it comes to texts, one of the most common representations is bag-of-words. Despite their popularity, bag-of-words models have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose an unsupervised algorithm that learns vector representations of sentences and text documents. This algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that our technique outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Le, Quoc and Mikolov, Tomas},
	editor = {Xing, Eric P. and Jebara, Tony},
	month = jun,
	year = {2014},
	note = {Issue: 2},
	pages = {1188--1196},
}

@article{rudkowsky_more_2018,
	title = {More than {Bags} of {Words}: {Sentiment} {Analysis} with {Word} {Embeddings}},
	volume = {12},
	issn = {1931-2458, 1931-2466},
	shorttitle = {More than {Bags} of {Words}},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2018.1455817},
	doi = {10.1080/19312458.2018.1455817},
	language = {en},
	number = {2-3},
	urldate = {2023-07-19},
	journal = {Communication Methods and Measures},
	author = {Rudkowsky, Elena and Haselmayer, Martin and Wastian, Matthias and Jenny, Marcelo and Emrich, Štefan and Sedlmair, Michael},
	month = apr,
	year = {2018},
	pages = {140--157},
}

@article{khodak_carte_2018,
	title = {A {La} {Carte} {Embedding}: {Cheap} but {Effective} {Induction} of {Semantic} {Feature} {Vectors}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	shorttitle = {A {La} {Carte} {Embedding}},
	url = {https://arxiv.org/abs/1805.05388},
	doi = {10.48550/ARXIV.1805.05388},
	abstract = {Motivations like domain adaptation, transfer learning, and feature learning have fueled interest in inducing embeddings for rare or unseen words, n-grams, synsets, and other textual features. This paper introduces a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings. Our method relies mainly on a linear transformation that is efficiently learnable using pretrained word vectors and linear regression. This transform is applicable on the fly in the future when a new text feature or rare word is encountered, even if only a single usage example is available. We introduce a new dataset showing how the a la carte method requires fewer examples of words in context to learn high-quality embeddings and we obtain state-of-the-art results on a nonce task and some unsupervised document classification tasks.},
	urldate = {2023-07-19},
	author = {Khodak, Mikhail and Saunshi, Nikunj and Liang, Yingyu and Ma, Tengyu and Stewart, Brandon and Arora, Sanjeev},
	year = {2018},
	note = {Publisher: arXiv
Version Number: 1},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, Artificial Intelligence (cs.AI)},
	annote = {Other
11 pages, 2 figures, To appear in ACL 2018},
}

@article{rodriguez_word_2022,
	title = {Word {Embeddings}: {What} {Works}, {What} {Doesn}’t, and {How} to {Tell} the {Difference} for {Applied} {Research}},
	volume = {84},
	issn = {0022-3816, 1468-2508},
	shorttitle = {Word {Embeddings}},
	url = {https://www.journals.uchicago.edu/doi/10.1086/715162},
	doi = {10.1086/715162},
	language = {en},
	number = {1},
	urldate = {2023-07-19},
	journal = {The Journal of Politics},
	author = {Rodriguez, Pedro L. and Spirling, Arthur},
	month = jan,
	year = {2022},
	pages = {101--115},
}

@book{firth_studies_1975,
	title = {Studies in {Linguistic} {Analysis}.},
	publisher = {Wiley-Blackwell},
	author = {Firth, J. R.},
	year = {1975},
}

@article{turney_frequency_2010,
	title = {From {Frequency} to {Meaning}: {Vector} {Space} {Models} of {Semantics}},
	volume = {37},
	issn = {1076-9757},
	shorttitle = {From {Frequency} to {Meaning}},
	url = {https://jair.org/index.php/jair/article/view/10640},
	doi = {10.1613/jair.2934},
	abstract = {Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.},
	urldate = {2023-07-19},
	journal = {Journal of Artificial Intelligence Research},
	author = {Turney, P. D. and Pantel, P.},
	month = feb,
	year = {2010},
	pages = {141--188},
}

@misc{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	urldate = {2023-07-19},
	publisher = {arXiv},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv:1907.11692 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{rogers_primer_2020,
	title = {A {Primer} in {BERTology}: {What} {We} {Know} {About} {How} {BERT} {Works}},
	volume = {8},
	issn = {2307-387X},
	shorttitle = {A {Primer} in {BERTology}},
	url = {https://direct.mit.edu/tacl/article/96482},
	doi = {10.1162/tacl_a_00349},
	abstract = {Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.},
	language = {en},
	urldate = {2023-07-18},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
	month = dec,
	year = {2020},
	pages = {842--866},
}

@article{garg_word_2018,
	title = {Word embeddings quantify 100 years of gender and ethnic stereotypes},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1720347115},
	doi = {10.1073/pnas.1720347115},
	abstract = {Significance
            Word embeddings are a popular machine-learning method that represents each English word by a vector, such that the geometry between these vectors captures semantic relations between the corresponding words. We demonstrate that word embeddings can be used as a powerful tool to quantify historical trends and social change. As specific applications, we develop metrics based on word embeddings to characterize how gender stereotypes and attitudes toward ethnic minorities in the United States evolved during the 20th and 21st centuries starting from 1910. Our framework opens up a fruitful intersection between machine learning and quantitative social science.
          , 
            Word embeddings are a powerful machine-learning framework that represents each English word by a vector. The geometric relationship between these vectors captures meaningful semantic relationships between the corresponding words. In this paper, we develop a framework to demonstrate how the temporal dynamics of the embedding helps to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States. We integrate word embeddings trained on 100 y of text data with the US Census to show that changes in the embedding track closely with demographic and occupation shifts over time. The embedding captures societal shifts—e.g., the women’s movement in the 1960s and Asian immigration into the United States—and also illuminates how specific adjectives and occupations became more closely associated with certain populations over time. Our framework for temporal analysis of word embedding opens up a fruitful intersection between machine learning and quantitative social science.},
	language = {en},
	number = {16},
	urldate = {2023-07-17},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Garg, Nikhil and Schiebinger, Londa and Jurafsky, Dan and Zou, James},
	month = apr,
	year = {2018},
}

@inproceedings{hamilton_diachronic_2016,
	address = {Berlin, Germany},
	title = {Diachronic {Word} {Embeddings} {Reveal} {Statistical} {Laws} of {Semantic} {Change}},
	url = {http://aclweb.org/anthology/P16-1141},
	doi = {10.18653/v1/P16-1141},
	language = {en},
	urldate = {2023-07-17},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
	year = {2016},
	pages = {1489--1501},
}

@inproceedings{blodgett_language_2020,
	address = {Online},
	title = {Language ({Technology}) is {Power}: {A} {Critical} {Survey} of “{Bias}” in {NLP}},
	shorttitle = {Language ({Technology}) is {Power}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.485},
	doi = {10.18653/v1/2020.acl-main.485},
	language = {en},
	urldate = {2023-07-17},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Blodgett, Su Lin and Barocas, Solon and Daumé Iii, Hal and Wallach, Hanna},
	year = {2020},
	pages = {5454--5476},
}

@article{de_marneffe_universal_2021,
	title = {Universal {Dependencies}},
	issn = {0891-2017, 1530-9312},
	url = {https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00402/98516/Universal-Dependencies},
	doi = {10.1162/coli_a_00402},
	abstract = {Abstract
            Universal dependencies (UD) is a framework for morphosyntactic annotation of human language, which to date has been used to create treebanks for more than 100 languages. In this article, we outline the linguistic theory of the UD framework, which draws on a long tradition of typologically oriented grammatical theories. Grammatical relations between words are centrally used to explain how predicate–argument structures are encoded morphosyntactically in different languages while morphological features and part-of-speech classes give the properties of words. We argue that this theory is a good basis for crosslinguistically consistent annotation of typologically diverse languages in a way that supports computational natural language understanding as well as broader linguistic studies.},
	language = {en},
	urldate = {2023-07-17},
	journal = {Computational Linguistics},
	author = {De Marneffe, Marie-Catherine and Manning, Christopher D. and Nivre, Joakim and Zeman, Daniel},
	month = may,
	year = {2021},
	pages = {1--54},
}

@book{jurafsky_speech_2023,
	series = {Third {Edition} draft ({January} 7th, 2023 version)},
	title = {Speech and {Language} {Processing}. {An} {Introduction} to {Natural} {Language} {Processing}, {Computational} {Linguistics}, and {Speech} {Recognition}},
	url = {https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf},
	author = {Jurafsky, Daniel and Martin, James H.},
	year = {2023},
}

@book{van_atteveldt_computational_2022,
	title = {Computational {Analysis} of {Communication}},
	publisher = {Wiley Blackwell},
	author = {Van Atteveldt, Wouter and Trilling, Damian and Calderón, Carlos Arcíla},
	year = {2022},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2023-07-17},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{bojanowski_enriching_2017,
	title = {Enriching {Word} {Vectors} with {Subword} {Information}},
	url = {http://arxiv.org/abs/1607.04606},
	abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character \$n\$-grams. A vector representation is associated to each character \$n\$-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
	urldate = {2023-07-17},
	publisher = {arXiv},
	author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
	month = jun,
	year = {2017},
	note = {arXiv:1607.04606 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: Accepted to TACL. The two first authors contributed equally},
}

@inproceedings{pennington_glove_2014,
	address = {Doha, Qatar},
	title = {Glove: {Global} {Vectors} for {Word} {Representation}},
	shorttitle = {Glove},
	url = {http://aclweb.org/anthology/D14-1162},
	doi = {10.3115/v1/D14-1162},
	language = {en},
	urldate = {2023-07-17},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
	year = {2014},
	pages = {1532--1543},
}

@book{haim_computational_2023,
	address = {Wiesbaden},
	series = {Studienbücher zur {Kommunikations}- und {Medienwissenschaft}},
	title = {Computational {Communication} {Science}: {Eine} {Einführung}},
	isbn = {978-3-658-40170-2 978-3-658-40171-9},
	shorttitle = {Computational {Communication} {Science}},
	url = {https://link.springer.com/10.1007/978-3-658-40171-9},
	language = {de},
	urldate = {2023-07-17},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Haim, Mario},
	year = {2023},
	doi = {10.1007/978-3-658-40171-9},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2023-07-17},
	publisher = {arXiv},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv:1301.3781 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@book{grimmer_text_2022,
	address = {Princeton},
	title = {Text as data: a new framework for machine learning and the social sciences},
	isbn = {978-0-691-20754-4 978-0-691-20755-1},
	shorttitle = {Text as data},
	abstract = {"From social media posts and text messages to digital government documents and archives, researchers are bombarded with a deluge of text reflecting the social world. This textual data gives unprecedented insights into fundamental questions in the social sciences, humanities, and industry. Meanwhile new machine learning tools are rapidly transforming the way science and business are conducted. Text as Data shows how to combine new sources of data, machine learning tools, and social science research design to develop and evaluate new insights.Text as Data is organized around the core tasks in research projects using text--representation, discovery, measurement, prediction, and causal inference. The authors offer a sequential, iterative, and inductive approach to research design. Each research task is presented complete with real-world applications, example methods, and a distinct style of task-focused research. Bridging many divides--computer science and social science, the qualitative and the quantitative, and industry and academia--Text as Data is an ideal resource for anyone wanting to analyze large collections of text in an era when data is abundant and computation is cheap, but the enduring challenges of social science remain." --Page 4 of cover},
	publisher = {Princeton University Press},
	author = {Grimmer, Justin and Roberts, Margaret E. and Stewart, Brandon M.},
	year = {2022},
	note = {OCLC: on1295105650},
	keywords = {Data processing, Social sciences, Machine learning, Apprentissage automatique, Informatique, Sciences sociales, Text data mining},
	annote = {Part I. Preliminaries. Introduction ; Social science research and text analysis -- Part II. Selection and representation. Principles of selection and representation ; Selecting documents ; Bag of words ; The multinominal language model ; The vector space model and similarity metrics ; Distributed representations of words ; Representations from language sequences -- Part III. Discovery. Principles of discovery ; Discriminating words ; Clustering ; Topic models ; Low-dimensional document embeddings -- Part IV. Measurement. Principles of measurement ; Word counting ; An overview of supervised classification ; Coding a training set ; Classifying documents with supervised learning ; Checking performance -- Repurposing discovery methods -- Part V. Inference. Principles of inference ; Prediction ; Casual inference ; Text as outcome ; Text as treatment ; Text as confounder -- Part VI. Conclusion},
}

@article{arendt_content_2017,
	title = {Content {Analysis} of {Mediated} {Associations}: {An} {Automated} {Text}-{Analytic} {Approach}},
	volume = {11},
	issn = {1931-2458, 1931-2466},
	shorttitle = {Content {Analysis} of {Mediated} {Associations}},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2016.1276894},
	doi = {10.1080/19312458.2016.1276894},
	language = {en},
	number = {2},
	urldate = {2023-07-24},
	journal = {Communication Methods and Measures},
	author = {Arendt, Florian and Karadas, Narin},
	month = apr,
	year = {2017},
	pages = {105--120},
}

@misc{watanabe_quanteda_2023,
	title = {Quanteda {Tutorials}},
	url = {https://tutorials.quanteda.io/},
	author = {Watanabe, Kohei and Müller, Stefan},
	year = {2023},
}

@misc{puschmann_automated_2019,
	title = {Automated {Content} {Analysis} with {R}},
	url = {https://content-analysis-with-r.com/},
	author = {Puschmann, Cornelius and Haim, Mario},
	year = {2019},
}

@article{welbers_extracting_2021,
	title = {Extracting semantic relations using syntax: {An} {R} package for querying and reshaping dependency trees.},
	volume = {3},
	issn = {2665-9085},
	shorttitle = {Extracting semantic relations using syntax},
	url = {https://www.aup-online.com/content/journals/10.5117/CCR2021.2.003.WELB},
	doi = {10.5117/CCR2021.2.003.WELB},
	language = {en},
	number = {2},
	urldate = {2023-07-24},
	journal = {Computational Communication Research},
	author = {Welbers, Kasper and Van Atteveldt, Wouter and Kleinnijenhuis, Jan},
	month = oct,
	year = {2021},
	pages = {1--16},
}

@misc{benoit_guide_2020,
	title = {A {Guide} to {Using} {Spacyr}},
	url = {https://spacyr.quanteda.io/articles/using_spacyr.html},
	author = {Benoit, Ken and Matsuo, Akitaka},
	year = {2020},
}

@article{van_atteveldt_clause_2017,
	title = {Clause {Analysis}: {Using} {Syntactic} {Information} to {Automatically} {Extract} {Source}, {Subject}, and {Predicate} from {Texts} with an {Application} to the 2008–2009 {Gaza} {War}},
	volume = {25},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Clause {Analysis}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198716000127/type/journal_article},
	doi = {10.1017/pan.2016.12},
	abstract = {This article presents a new method and open source R package that uses syntactic information to automatically extract source–subject–predicate
              clauses
              . This improves on frequency-based text analysis methods by dividing text into predicates with an identified subject and optional source, extracting the statements and actions of (political) actors as mentioned in the text. The content of these predicates can be analyzed using existing frequency-based methods, allowing for the analysis of actions, issue positions and framing by different actors within a single text. We show that a small set of syntactic patterns can extract clauses and identify quotes with good accuracy, significantly outperforming a baseline system based on word order. Taking the 2008–2009 Gaza war as an example, we further show how corpus comparison and semantic network analysis applied to the results of the clause analysis can show differences in citation and framing patterns between U.S. and English-language Chinese coverage of this war.},
	language = {en},
	number = {2},
	urldate = {2023-07-24},
	journal = {Political Analysis},
	author = {Van Atteveldt, Wouter and Sheafer, Tamir and Shenhav, Shaul R. and Fogel-Dror, Yair},
	month = apr,
	year = {2017},
	pages = {207--222},
}

@article{fogel-dror_role-based_2019,
	title = {Role-based {Association} of {Verbs}, {Actions}, and {Sentiments} with {Entities} in {Political} {Discourse}},
	volume = {13},
	issn = {1931-2458, 1931-2466},
	url = {https://www.tandfonline.com/doi/full/10.1080/19312458.2018.1536973},
	doi = {10.1080/19312458.2018.1536973},
	language = {en},
	number = {2},
	urldate = {2023-07-24},
	journal = {Communication Methods and Measures},
	author = {Fogel-Dror, Yair and Shenhav, Shaul R. and Sheafer, Tamir and Van Atteveldt, Wouter},
	month = apr,
	year = {2019},
	pages = {69--82},
}

@article{burggraaff_through_2020,
	title = {Through a different gate: {An} automated content analysis of how online news and print news differ},
	volume = {21},
	issn = {1464-8849, 1741-3001},
	shorttitle = {Through a different gate},
	url = {http://journals.sagepub.com/doi/10.1177/1464884917716699},
	doi = {10.1177/1464884917716699},
	abstract = {We investigate how news values differ between online and print news articles. We hypothesize that print and online articles differ in terms of news values because of differences in the routines used to produce them. Based on a quantitative automated content analysis of N = 762,095 Dutch news items, we show that online news items are more likely to be follow-up items than print items, and that there are further differences regarding news values like references to persons, the power elite, negativity, and positivity. In order to conduct this large-scale analysis, we developed innovative methods to automatically code a wide range of news values. In particular, this article demonstrates how techniques such as sentiment analysis, named entity recognition, supervised machine learning, and automated queries of external databases can be combined and used to study journalistic content. Possible explanations for the difference found between online and offline news are discussed.},
	language = {en},
	number = {1},
	urldate = {2023-07-24},
	journal = {Journalism},
	author = {Burggraaff, Christiaan and Trilling, Damian},
	month = jan,
	year = {2020},
	pages = {112--129},
}

@article{kroon2019,
	title = {Clouded reality: News representations of culturally close and distant ethnic outgroups},
	author = {Kroon, Anne C. and Trilling, Damian and Meer, {Toni G. L. A. van der} and Jonkman, {Jeroen G. F.}},
	year = {2019},
	month = {11},
	date = {2019-11-19},
	journal = {Communications},
	volume = {0},
	number = {0},
	doi = {10.1515/commun-2019-2069},
	url = {http://www.degruyter.com/view/j/comm.ahead-of-print/commun-2019-2069/commun-2019-2069.xml}
}
